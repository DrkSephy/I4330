############################# David Leonard 		   ## tutnese.py    		   ## *~-drksephy.github.io*~- #############################import retoken_exprs = [	(r'squab', 'bb'), 	(r'squac', 'cc'),	(r'squad', 'dd'),	(r'squaf', 'ff'),	(r'squag', 'gg'),	(r'squah', 'hh'),	(r'squaj', 'jj'),	(r'squak', 'kk'),	(r'squal', 'll'),	(r'squam', 'mm'),	(r'squan', 'nn'),	(r'squap', 'pp'),	(r'squaq', 'qq'),	(r'squar', 'rr'),	(r'squas', 'ss'),	(r'squat', 'tt'),	(r'squav', 'vv'),	(r'squaw', 'ww'),	(r'squax', 'xx'),	(r'squay', 'yy'),	(r'squaz', 'zz'),	(r'bub'  , 'b'), 	(r'coch' , 'c'),	(r'dud'  , 'd'),	(r'fuf'  , 'f'),	(r'gug'  , 'g'),	(r'hash' , 'h'),	(r'jug'  , 'j'),	(r'kuck' , 'k'),	(r'lul'  , 'l'),	(r'mum'  , 'm'),	(r'nun'  , 'n'), 	(r'pup'  , 'p'),	(r'quack', 'q'),	(r'rur'  , 'r'),	(r'sus'  , 's'),	(r'tut'  , 't'),	(r'vuv'  , 'v'),	(r'wack' , 'w'),	(r'xux'  , 'x'),	(r'yub'  , 'y'),	(r'zug'  , 'z'), 	(r'a'    , 'a'),	(r'o'    , 'o'),	(r'e'    , 'e'),	(r'i'    , 'i'),	(r'u'    , 'u'),	(r' '    , ' '),	(r','    , ','),	(r'!'    , '!'),]language = {	'b': 'bub',	'c': 'coch',	'd': 'dud',	'f': 'fuf',	'g': 'gug',	'h': 'hash',	'j': 'jug',	'k': 'kuck',	'l': 'lul',	'm': 'mum',	'n': 'nun', 	'p': 'pup',	'q': 'quack',	'r': 'rur',	's': 'sus',	't': 'tut',	'v': 'vuv',	'w': 'wack',	'x': 'xux',	'y': 'yub',	'z': 'zug'}doubleLanguage = {	'squab': 'bb', 	'squac': 'cc',	'squad': 'dd',	'squaf': 'ff',	'squag': 'gg',	'squah': 'hh',	'squaj': 'jj',	'squak': 'kk',	'squal': 'll',	'squam': 'mm',	'squan': 'nn',	'squap': 'pp',	'squaq': 'qq',	'squar': 'rr',	'squas': 'ss',	'squat': 'tt',	'squav': 'vv',	'squaw': 'ww',	'squax': 'xx',	'squay': 'yy',	'squaz': 'zz'}vowels = ['a', 'o', 'e', 'i', 'u']def encode(phrase):	lowerPhrase = phrase.lower()	words = lowerPhrase.split()	# print words	translation = []	for word in words:		currWord = ''		for i in range(len(word)):			# Store current letter			currLetter = word[i]			nextLetter = ''			prevLetter = ''			# Check if character is '|'			if word[i] == '|':				raise Exception('Illegal character: |')			# Get the next letter			if i < len(word) - 1:				nextLetter = word[i + 1]			# Get the previous letter if possible			if i > 0:				prevLetter = word[i - 1]			# Handle double character case			if currLetter == nextLetter and currLetter not in vowels:				currWord += 'squa'			# Previous character case			# Now we insert the repeated character			elif currLetter == prevLetter:				currWord += currLetter			elif currLetter in language.keys():				currWord += language[currLetter]			else:				currWord += currLetter		translation.append(currWord)	return ' '.join(translation)def decode(phrase):	translation = tutneseLex(phrase) 	newTranslation = ''	for char in translation:		newTranslation += char	return newTranslationdef tutneseLexer(characters, token_exprs):    pos = 0    tokens = []    while pos < len(characters):        match = None        for token_expr in token_exprs:            pattern, tag = token_expr            regex = re.compile(pattern)            match = regex.match(characters, pos)            if match:                text = match.group(0)                if tag:                    token = tag                    tokens.append(token)                break        if not match:            sys.stderr.write('Illegal character: %s\n' % characters[pos])            sys.exit(1)        else:            pos = match.end(0)    return tokens# Create our lexer functiondef tutneseLex(characters):    return tutneseLexer(characters, token_exprs)print encode('Over hill, over dale, Thorough bush, thorough brier, Over park, over pale, Thorough flood, thorough fire!')print decode('ovuverur hashisqual, ovuverur dudalule, tuthashorurougughash bubusushash, tuthashorurougughash bubrurierur, ovuverur puparurkuck, ovuverur pupalule, tuthashorurougughash fufluloodud, tuthashorurougughash fufirure!')